{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains testing for predicting straight line parameters\n",
    "# Works like a charm... :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from hough import *\n",
    "from conformal_map import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "dims = 50\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    train_Y.append([])\n",
    "    image = np.zeros((dims, dims))\n",
    "    nr_lines = random.randint(1, 20)\n",
    "    for j in range(nr_lines):\n",
    "        k = random.uniform(0, 1)\n",
    "        m = random.uniform(0, 1)\n",
    "        train_Y[-1].append([k, m])\n",
    "        for x in range(dims):\n",
    "            y = k * x + m\n",
    "            image[x, int(y)] = 1\n",
    "    for j in range(len(train_Y[-1]), 20):\n",
    "        train_Y[-1].append([None, None])\n",
    "    train_X.append(image)\n",
    "    \n",
    "train_X = np.reshape(train_X, (N, dims, dims, 1))\n",
    "train_Y = np.reshape(train_Y, (N, 20, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential() \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(dims, dims, 1)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(20))\n",
    "    model.add(layers.Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
    "    model.add(layers.LSTM(20))\n",
    "    #optimizer = keras.optimizers.RMSprop(learning_rate=0.00001) #0.00001 works good\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 46, 46, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                1354260   \n",
      "_________________________________________________________________\n",
      "lambda_12 (Lambda)           (None, 20, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 20)                1760      \n",
      "=================================================================\n",
      "Total params: 1,365,588\n",
      "Trainable params: 1,365,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_batch = train_X[:1]\n",
    "#example_result = model.predict(example_batch)\n",
    "#example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50, 50, 1)\n",
      "(100, 20, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected lstm_28 to have 2 dimensions, but got array with shape (100, 20, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-d8c52210b07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected lstm_28 to have 2 dimensions, but got array with shape (100, 20, 2)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "history = model.fit(train_X, train_Y, validation_split=0.1, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50, 50, 1)\n",
      "[[[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]]\n",
      "[[[0.3061403895092857 0.6406105513320187]\n",
      "  [0.8145927518071947 0.8621164887354286]\n",
      "  [0.28981413584070914 0.9414974905417384]\n",
      "  ...\n",
      "  [None None]\n",
      "  [None None]\n",
      "  [None None]]\n",
      "\n",
      " [[0.9551329635092358 0.2102555992806019]\n",
      "  [0.8206610938658528 0.020946086484476267]\n",
      "  [0.16792042549871644 0.06079393647155307]\n",
      "  ...\n",
      "  [None None]\n",
      "  [None None]\n",
      "  [None None]]\n",
      "\n",
      " [[0.8322236471086458 0.9103182543888078]\n",
      "  [0.44419415872966694 0.25386849507318787]\n",
      "  [0.3334136044900199 0.8580983520702222]\n",
      "  ...\n",
      "  [None None]\n",
      "  [None None]\n",
      "  [None None]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.3112800063555591 0.7749115778784139]\n",
      "  [None None]\n",
      "  [None None]\n",
      "  ...\n",
      "  [None None]\n",
      "  [None None]\n",
      "  [None None]]\n",
      "\n",
      " [[0.9762179901430145 0.2710044642371936]\n",
      "  [0.45972098803604566 0.24430440824506183]\n",
      "  [0.5284522411830501 0.8689085682696035]\n",
      "  ...\n",
      "  [None None]\n",
      "  [None None]\n",
      "  [None None]]\n",
      "\n",
      " [[0.025609203120489754 0.3191634258906004]\n",
      "  [0.4086183226563731 0.1443614406610806]\n",
      "  [0.15525387746569164 0.35588511012168667]\n",
      "  ...\n",
      "  [None None]\n",
      "  [None None]\n",
      "  [None None]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "prediction = model.predict(train_X)\n",
    "#print(prediction - train_Y)\n",
    "print(prediction)\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]]\n"
     ]
    }
   ],
   "source": [
    "k = random.uniform(0, 1)\n",
    "m = random.uniform(0, 1)\n",
    "image = np.zeros((dims, dims))\n",
    "for x in range(dims):\n",
    "    y = k * x + m\n",
    "    image[x, int(y)] = 1\n",
    "    \n",
    "predicted_params = model.predict(np.array([np.reshape(image, (dims, dims, 1))]))\n",
    "print(predicted_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-ff4cf6a0a6d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredicted_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredicted_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "predicted_image = np.zeros((dims, dims))\n",
    "for x in range(dims):\n",
    "    y = predicted_params[0][0] * x + predicted_params[0][1]\n",
    "    predicted_image[x, int(y)] = 1\n",
    "plt.matshow(predicted_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation predicted from neural network: y = 0.41867995022983684x + 0.673239055540219\n"
     ]
    }
   ],
   "source": [
    "print(\"Equation predicted from neural network:\", \"y =\", str(k) + \"x\", \"+\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
