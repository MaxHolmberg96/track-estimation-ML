{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from hough import *\n",
    "from conformal_map import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prefix = 'event000001000'\n",
    "hits, cells, particles, truth = load_event(os.path.join('train_100_events', event_prefix))\n",
    "cond = (hits['volume_id'] == 8) | (hits['volume_id'] == 13)# | (hits['volume_id'] == 17)\n",
    "selected_indices = hits.index[cond].tolist()\n",
    "selected_hits = hits.iloc[selected_indices]\n",
    "selected_truth = truth.iloc[selected_indices]\n",
    "track_id = selected_truth.particle_id.unique()[1323]\n",
    "track = selected_truth[selected_truth.particle_id == valid_tracks[101]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2df5SV5XXvv3t+gEhkASJWBrijBnXh1UqkokvaS5PSGCcl09xKanA1tyah7VpVCY1kcLgRUwkTuCHWJnfdoultsiAGtObEdlCKJtwbswDFDEpN5IJmggwu8efSgjIw7PvHeV85HM6Z8zzP+/x6z9mftVjMvHN+7POe9/0++9l7P/shZoYgCILQWDSFNkAQBEHwj4i/IAhCAyLiLwiC0ICI+AuCIDQgIv6CIAgNSEtoA1SZMGECt7e3hzZDEAQhVzzzzDOvM/M55cdzI/7t7e3YuXNnaDMEQRByBRH9ptJxCfsIgiA0ICL+giAIDYiIvyAIQgMi4i8IgtCAiPgLgiA0ILmp9hGEkMxdsxV7Dx0+7fi1F47H+i9eAwAo9A3gSxt2obRVIgH41meuQOeMNj+GCoIilJeunjNnzmQp9RR0WXDfNvz8xTcr/i0V7uEeE4JpE0dj4lkjT7FpRDNh1Z/8tgwigjZE9AwzzzztuIi/kHcKfQNYvGEXToQ2xCOtTcDqG2RGIdRGxF+oK2Lz1mODCFgwayru7rwstClCYKqJv8T8heioFl8X1GEG1m3fj3Xb95/2N5k1CIB4/kIEzFqxBa++OxjajIblpqtlhlDPiOcvRIGEa+Kj2gzhjGbCCyuuD2CR4AMRf8Epywq7KwqLED/vDzHau3oBFCuQtiyeE9YgwSoi/oI16smrT0Mh1UJSTQDWlNTvF/oGsPyR5/H2e8dOeVwqmnnPY+w9dPiDgQAorl/4dU9HOIOEzEjMX7DC5Xc+hneODoU2oyZntjbh65++POpkZ94GilGtTVgZ+TltZJyWehLRWAD3A/jPABjAzQD2ANgAoB1AP4D5zPxW8vilAD4PYAjArcy8udZ7iPjHQaFvAHf9y/N468ix2g/2DAFY0CDJy1jDaePObMXbR45h0thRuP3jF8uAEAGuxf97AH7GzPcT0QgAZwK4A8CbzNxDRF0AxjHzV4hoOoAHAFwFYBKAxwFcxMzDuo0i/uG5pHsT3h8KM1OUmLM6ldpMhOQeaW8RFGfiT0RjADwL4AIueTEi2gNgDjO/QkTnAdjKzBcnXj+YeWXyuM0AljPztuHeR8Q/DKFCEM0EfHO+iIZtlhV2Y/32/UEGBhkEwuBS/K8AsBbALwH8NoBnANwGYICZx5Y87i1mHkdE3wawnZnXJce/C+BRZn6owmsvBLAQAKZOnXrlb35TcTcywRIhE7ZSa+6fkN93MxFunDVFvnMPuKzzbwHwEQC3MPMOIvo7AF3D2VLhWMURiJnXojiwYObMmbHMYusS30JQ2g1TCMNw59/1jG+I+YP1BTIjCIMN8T8A4AAz70h+fwhF8X+ViM4rCfscKnn8lJLnTwZw0IIdggE+4vhjRjbjubuuc/oegl3S/IqP1deLNuzCyk2/xI7uuU7fRzgVWwnfnwH4AjPvIaLlAEYnf3qjJOE7npmXENGlAH6AkwnfJwBMk4SvHwp9A7jj4edw5Jj7HphtUvFRNxT6BrB68x4cfPs9tDQBri6f0SOacWRwSKqFLOK62ucKFEs9RwB4CcCfo7gOZiOAqQD2A7iBmd9MHt+NYjnocQCLmPnRWu8h4p8dl7X45541Qjy3BsNHualcV9mRls4NTunqTNtI/F5wnTOSggBzRPwbDJfhHRF7oRauBgNJDusj4t8AuJqGNxGwRmruBQNchoZk4Z8a1cS/KYQxgn1c3WRjR7WK8AvG3N15Gfp7OnDT1VOtv/beQ4dxSfcm66/bKIjnn3NchHckrCO4ptA3gEUbdll7PblmqyNhnzqj0DeAJQ89i0FLNfoSSxVCYHMxmawnqYyIf51gO5FGAL4lwl+TWiLV2gSMHz2i6oKoUmFaVtiNB3a8jCFmaXOQYHMQEEfmVET86wBbwi8eUpFY++anA3K6qKrRFjzZus7zsHeDD0T8c0yhbwB/s3EXskZ4Gi0uGmvPexs0gndr6/tr9KogEf8cYispVq8Xf8j9BWKm3hZE2egv1ELAvpWNue2kiH+OsOXx1NP2evW0P7BP6m22l/XeaKTd3lJE/HOCDeHPez8U22WAwunkfXZgI1/TCKEzQMQ/F2QV/jzf0PUcn4+ZPIcEbcwG83zPqCLiHzE2vJg8XcQSwombPM0cC30DuP3BXZlaTOfp3jFBxD9CbHi7485sxZ1/dGlupq95EX7bAljoG0D3j3bj8KCbltouyGO+IEv32nodBET8IyNrBUNeLtRYwzn9PfFWfsR2zvIWGsoyAORp1qOKiH9EZAnz5CFJVegbwJc27Kq8MbNj8uit6hDDwrQ8LBLMUgact8GuFiL+kXB+V6+xKOZB+H3s+VrOGc2EF1Zc7/U9Y6PQN4DljzyPt9875u09Yx8Essyg6mkAEPEPTNZYd8zC79MbzUu4KySFvgF85Z+fw9Hj7vdpBuIOoaWYOCX14lSI+Acii+gTAQtmxSd2vpOXIvh28JVLiNVrNp2V5n1hmIh/ALIIf6yxa9fx/Dx4kXmn0DeAxRt2wfW8IMbvshFzAc7Fn4iaAewEMMDMnySi8QA2AGgH0A9gPjO/lTx2KYDPAxgCcCszb671+nkUf9OqgxgvMtfefj1WWeSBQt8AVm/eg4G333Py+jF+r1nClLE6ZcPhQ/wXA5gJYEwi/qsAvMnMPUTUBWAcM3+FiKYDeADAVQAmAXgcwEXMPKyq5En8TT3+GHvru6rLj3GAE9y01ohxAMgy6MWcf6uEU/EnoskAvgdgBYDFifjvATCHmV8hovMAbGXmixOvH8y8MnnuZgDLmXnbcO+RF/E3FcvYPAoXSVwR/PzgMmkcWw7HpAIvxpBWNVyL/0MAVgI4C8CXE/F/m5nHljzmLWYeR0TfBrCdmdclx78L4FFmfmi498iD+JvGE+vhZhiO2AY2QR/bM4LYKmlMQ7R5mAVUE/8WCy/8SQCHmPkZIpqj8pQKxypqDREtBLAQAKZOnWpsow9MhD+2OuksKyNLaW0CVt8Q/00hqNM5ow2dM9qsDQLvDzHau3qj8aD7ezqMrv/0XOTxWm+y8BrXAphHRP0Afgjgo0S0DsCrSbgHyf+HkscfADCl5PmTARys9MLMvJaZZzLzzHPOOceCqW5YcN82I48/BuEv9A2gvavXivCf0Uzo7+nA3q935PJmEGrTOaMN/T0duPbC8VZer72rF4W+ASuvlZX+ng6ce9YI7efltf241VLPxPNPwz6rAbxRkvAdz8xLiOhSAD/AyYTvEwCm5TXhaxLjjyEBZnsaX0/xfJulkC0EHK9wi8VwDdjAdkFALNeRbs4rFrsr4aXOv0z8zwawEcBUAPsB3MDMbyaP6wZwM4DjABYx86O1XjtW8df1mGOIEdoS/tjCVirkpasokL9cia01ILEMjLqLwmLL3aXIIi/LXH7nY3jnqF7NewzxTRurPPMkSibfU2zkbYVpPe1PYRIOjcX2FBF/i5gISugLwtbS/hhmLtUI0VQuNLFVzaTYmF3GMLM0/Ryh7/dSRPwtousNhPSUbYQ5Ylx8BsTR3jgmYh6YsxYUhBTTQt8A7nj4ORzR3C4shpk+IOJvjTzF+LMKfwyeVyki9vrE9B1m6asDxJFU1b3/YxgAqom/jVLPhmBZYbfWFz9mZDP6e8KWPGYR/mkTR0cjGkBROET49Xnn6BDau3rx4aV21nBk4YUV12PaxNHGz9976DCWFXZbtEgf3RLXWMpYKyGevwK6HnToeF/WeGtoD6sRY/e+iCFZnzX/FNqbztPsH5CwjzG6QkoAfh3w4swytW4hYN/KMLbHHtIxFc3yHbbGndmK6eedFU25aeiwkOlAkLcBIOR5FvE35KLuTRjUENNQXn8Wbz90XXVI4R89ohkr/viyoJ5ZoW8ASx56Vus6s03IGUFer11dRyuUrSL+BuhelHkU/pA3va/wTmjvNgu+dt9KCeVRZ/mcoctddWYBIc6viL8mOoIaOo566VcfM9pkJURs31bzuFqE/k5c42O25NtTzTIAhMyz6TgxIeL/Iv4a6N5YIeOPpt6z74vQpQcbOv4bEhebr5Tj+/yafqaQ10HM3r+IvyK6wh8qpGDq+YWw11V4J3RVUmy4nA2E8Fh1Y+ohiy10nRufMxURf0XysIjDtKLHt622xSjPsfsQ2D7/IRKWJtd6KKcg1gFAxF8RVfEP5WWYrtr1KZy2Rce31+mjGZzP78P252kmwo2zpnjzXE1mjiGTwLGFgET8FdC5yELFF00Spj6FxmZC15Vn5LuCxgQXn31ZYTce2PEyhizd8z4dIBOHIlTSX+f6EvFXwLX450H4dW8A39N0G8Lv2mZf1UY2cXW92ToXPu+HPIRlAXU7fYR+RPyHQSeUEircozt19xn3zNqwC7DvpdVjiwgX36mtWZAvkdWtBMpDQYbrGYqI/zDoeBMh6olj7SViSzhsXfwfXtpbccvEesbWubORp/E1AORlPw0dB8TlACDiXwWdiz7EBXR+V6/Wtng+4py2tkK0KRZ5DOfYxOaAn+Vc+poZmwz0Ie7fGOL/Iv5VUL3QQ9Q563rWPqa4WYXf1g2oOyg2CrYEJGuFkI9ZgMm1GCIHcOHSXqhERV0NTiL+VVAR/9EjmvH81/zHDXU8MF8x/ixeYdaLu9G9exOyiF1eWi/rXBchnDidPIWLcybiXwFV7zHEBaMzrfUl/FkSu3kW/qwVSKHbVWcVlCyzAB8DgO4gFcL7V71+cyX+RDQFwPcB/BaAEwDWMvPfEdF4ABsAtAPoBzCfmd9KnrMUwOcBDAG4lZk313of2+KvekOGWC2oW6ni+mIO2XLXR+8aINyiIB8LylJCDQI+xFbHOQixUll1gHJhm0vxPw/Aecz8CyI6C8AzADoB/DcAbzJzDxF1ARjHzF8houkAHgBwFYBJAB4HcBEzD3tV2RR/VUEJUSamG8d0vQGL6Q2fddC0UT5ajdD7F6jgKqcRagBwnWzNw6ZLoQYAb2EfIvoxgG8n/+Yw8yvJALGVmS9OvH4w88rk8ZsBLGfmbcO9rk3xn/7fH8WRYydqPi72boauL2DTWvksF68L0Q+9u1oWbFVWVcL0+jYtqXX9PejePyFm9aqDuk3t8bKBOxG1A5gBYAeAc5n5FQBI/p+YPKwNwMslTzuQHKv0eguJaCcR7Xzttdes2aki/Fk2mjZl9eY9yo+95zNXOBc0E+FvIUQj/Gc0E/p7OnIr/ACw/ovXoL+n45R/tjDNo+xb2WF0fzCK37ErOme0aZ2fEHmYb33mCqXH+diovsXWCxHRhwD8M4BFzPwOEVV9aIVjFe94Zl4LYC1Q9Pxt2FnoG1B6XIiugANvv6f0uGkTRztPQM9ds1X7OVnWGCwr7LYi/K7CCyYeuKsGaP09HdZyIe1dvUYDSun9oTOIuArllTJt4uho94PunNGm9L2t277f+ZoEK+JPRK0oCv96Zn44OfwqEZ1XEvY5lBw/AGBKydMnAzhoww4VfCQPTZi1YovyY10PTAvu26Z182SdztuIb9vyiG1WFQ0xY932/VXjvFls7pzRhs4ZbVbCQqYDQIqu2M5ascVpzmXL4jnK3+PcNVsbdk+IzGEfKrr43wXwK2ZeU/KnRwB8Lvn5cwB+XHL8T4loJBGdD2AagKey2qHCgvuGTSt8wLlnjXBsyaksK+zWWgbukg8v7dUSk2svHG8s/O1dvWjPKPznnjUik3ClNqT/fGLjvdOwUNYwZZbPriuer7476DT8A6iHbfceOqwcDbCF6j18+Z2PObXDRrXPbAA/A7AbxVJPALgDxbj/RgBTAewHcAMzv5k8pxvAzQCOoxgmerTW+2RN+IZeaDEcsfT/NknkmdqTVWizhHfysFgsSwgta1M703UtJufV5fUc8966qjM2GxWHDb/I69qenyjF1H33ANdZoOK6XM5Xu9ws4htqsAlJiM9sKoa6C9pcr69QdfpCVIT5WvjlpdonZg4qCP+0iaO9b/7wwI6Xaz8IRQ/Ad1Oq4QixStLkPUOEc2xj+hn6ezrQUrXuYnhMc2NbFs/R+p5cJ4BVB7B8uMB2aRjxVyFE4kd1VyXXi810tq80Ff65a7Yaidi0iaO137MeRL8ck8+0b2WHcZ4oy/k7o1l91FHNxZmiYYpXQpSTl9IQ4l/oG4hyZFdNet109VSndujc5KZT4/O7eo3K7/p7OrQG5XoU/XLSz6haIVa6VkAX06SjTijH1SK2lG/OV6utdz0IlaN6XbtKSFur84+ZGMs7F9y3TXnKG0uc39RT8ZUIdCX6NlpouLDt1XcHtcs0+3s6tGx55+iQcSmoTgnoJd2bnMX+O2e04Ts/3VvTFteDUCVuunpqzZzf7Q89C0A9hKVK3Sd8VbPqse5367IKQbe+3kQATCqIdCscbApreeLP5muXnj/bDet0vhvT9zb5/nUqblwnf1W+S9e9siqhYte4M1vR99U/NHr9agnfuvf8VUfzWBt9uSw/cy38AIx6wPgW/lLBdxk2qvS6/SXvm/W1VXvVpNeU7gBgMgPY0T1XebBxnfxVmfXEug3oW0eOWX/Nhoj555UQFTWV8GWHbmI3q2CmcXBGuFxB+r43XT0V/T0dGDOy2fi19h46rJxHSvvg+FjQqOPA+F5wVQnXi6vKCZX4FfFvUFRvsqYMlRK6i9d0E7smpNVKqRcYS3J43fb9aO/qxdc6L0N/T4dxkv/9Icb5Gp9Jd8Zr2nBMteLo9gfD5+d87a+QEqq9hIg//Ldz0Onj4wrVKf9nZ5mJkMtVyyaCXdrhMybRL2fRhl1o7+rF3ckgoFMymcIo5lpU0Tn/pts6qq6fUWi4K1iirsVf1UvxGe9X7eNjctOroiN8JpVGOq+v+zlNK4deWHE9LuneFK3ol5MOUC+suN4o7Hac9bx0nbUApudQNbzhMuxyj2JLZd+4LueuRF2L/3rFXXN8ouo5uap60BEEE9HRbQWt8zl1RSeNo6fP9dFO2DbpZzap09fx0td/8RrnA8CWxXOUBoB3jg45GwA6Z7QpDQA6oTMbqDhZOrM5Fepa/FVu9RirfFwmgFTbSZjaoLOQS0fMdLtA9vd0fHBD5cXbr0ap/S5DZOliMJeoxrddxt1VEtAxugm2K5HqWvzzissEkGo7CddJKB2R0VkQV/7aeRf+FF8DgNA4iPg3GFmqd0Khs/KyHoU/pXwAcBWyNG0GJ+QLEf8G44TD+ayq2OqElEyrhupN+FNKP9eO7rnKiUKd86G6wtVkq0/A/YZEKrRGqHy+k74RngLBFarJXtcXoYuQUiwL4nxQKuSu+j6pDNCmu2Ct/+I1FTfy9snqG+Kr+vHdsr1uxV+lQ5/vlXUqFQwubVKt/nBZ3uliYCkX/nr1+quhOvDpnJcti+cohZVM+xOpdId1+T2qJH1jvI5sVkHVrfirxImPDPpdUaJSwRB6M2mXU3KC3sCiMlMJUR8dA+XC5KJ+PcZKuEbHZhVU3Yq/Ciq7ezUaLncy090LQGWmUj6YqHprLhfRhcDn/rNCfdDQ4j9p7KjQJggZMPV2+3s6ol7wpRrGKQ9tNlLeQ8hO3Yq/imd3+8cv9mCJ4Ipyb9e06VhsqLZONtl8RDeOXV/zo/jxWYUUTPyJ6Doi2kNE+4ioy/brq3h2MlWuL1RWL9e7d2w79m+6bacKofM1MZScltM+wV8RShDxJ6JmAN8B8AkA0wHcSETTQ9jSKLjsk67bekEFk6oG1dXLMVZxVMJkoArh0Jj2wVFJ/puuJVBBJb/lu7e/yT7XpoTy/K8CsI+ZX2LmQQA/BPCpQLY0BKs373H22i7i57WqGkyEMRavPxY7bOEye+JTDCvhu7e/T0Jt49gGoHSOfgDArPIHEdFCAAsBYOrUxizps4VUNqmjusn5TVdPNa42EoTQhBL/Snmk0xwIZl4LYC1Q3MDdtVH1zKSxozAgA4AS1QR8XtOTWNKyEZPodRzkCVj11Hy0b5/t2TpBsEOosM8BAFNKfp8M4KDNN/Ddpz92XFY2qVRW6VaN1NrL1iTPkMUrn9f0JHpa78fkptfRRMDkptfR03o/5jU96dUOob7x2VQvlPg/DWAaEZ1PRCMA/CmAR2y+wZhRrTZfzgsuqw9UEoGmF57Khiy6VSPP3XXdsH/PkmcwqYhZ0rIRZ9KpO7CdSYNY0rLR2I5axDBIqLRJMd10XmU7U5f3hEppsO8WMLZ79g9HEPFn5uMA/hrAZgC/ArCRmZ+3+R6hE0UmmNRt28TlhedDyFRmex9e2mtUETOJXq9y/A3t13KJ7fOsck3WGqirobKdqcsV5yoryEO3W3FJsDp/Zt7EzBcx84XMvCKUHUJ+KS8DVOlFYzrAHeQJVY6fbfaCw6CacM5zxZMQnrpd4SvEh+2aadPZXXtXb83Qz7ymJ/HkiFvx0sjP4skRt+KJE1fgCJ86szjCI7Dq+HwjG2rZ5/N5QmMi4i94w0XNtOmAMlwr4krJ3Rua/y8eHPo9HDgxASeYcODEBHQd+wIeOVG/1T710i5DqEzdir/vRE294HIlsC4qIYryAcVGWKNacvdjTbswe/BeXHB0PWYP3htU+H3sYaC6/4MJvlfOCqdTt+IfY6JGpZeJS29LZUBctGGX0QCgWpXhohVEufBlLZfLS3I3RfWa0RkYVcXZ9FSrzALrre12LVQqq2xSt+Kvgu9prUovE5fe1pbFc5QHAF3Wf/EapQHg/SHW6teiWkZYOgCo7kFbDZ/JXRNKRXxZYbeTa0Y1RGfS+E3VuVApITblw0trz5R8N35Tqayy2bivocXfpdDGissZkWpZnk6iVqeMsHQAUPVyyxO785qexKrj870ld3Up/VyFvgHla9hFlY+pZ+6yz5QqKlVfLstMTbHZuK+hxV/IBzqtf3UGgHlNT2J16z+ckthd3foPAICuY1+ILrlb6onOWrHFeP/cWqh26TT1zKXNSByI+AtB0ElQ6m4orzoA3NnyfYykU8MbI2kId7Z8H4+cmB1NchcoCn/qibZ39SotkErR8fpnrdjitEunEA8i/p5RmSjHUHHjo2ZcJ/avG7ZQGQDG039oHQ9Ff0/HKcKvg07V29w1W7UGFRNUZxUuk70qbSV8E6Kstq7FXyVc4PtC+HVPR80BwLTiRhXVRJbJJh06DfX2Hjqs9R4mA0Aqlnld2ZraXfpZVJk2cbRyjmfBfdu0cjEmjRMLfQPKswqXyV6VAc53pZFK7sZ2Arquxf/uzstqDgCvvjsYZACohat4LlBMZKl4hCbT/x3dc7WEgaE3AJtUO7R39WLumq3o7+k4ZRB4Cx+q+Phqx31COFX4TdBJ7uv0lWohtVYa5SxWvKZtb0VZSgyVRqbYTkDXtfgDavFi11PdGFEVBhPh2dE9V8vT1jn/nTPajMRh76HDaO/qRaFvAP09HZg2cTSWH/szDPKpW1oMcguWH/sz7de3xblnjUB/Twd+nfT3MRV+nfOvE34jmJfSnlB8fZdbUapUGvncRD0koTZzEYRTaO/qVRaszhlteHDnfqMuqIs27MKiDbtwz2euQOeMOfhSN/A3zRsxid7AQT4bq47PD5LcHTOy+YOy1iz5lnPPGqHlleu+l+mG7qrv43LDeECt0ui4yihVBzTIGJdPVBai+MCH95m+j2riS3VRWUp5Pf9PHvw22rt68aOh2Zj8tRfRdNfbQap6Uk//3aNDmTx9oBjjdyn8psTScE51hjNp7Ci3hpThcpP64RDPP2J8buxQi8vvfMy4b7sO67bvxyN9A0rvpVoBkzZqS/v1TKbiLlw4BjxyYnbVyiAXolX++q++O2jlfbJUQ6liknB00c7DFNWEtstd78op9A0E23uEmCNSmGGYOXMm79y50+i5C+7bVjNEcEYzeU/yqN6ALitVdESgNDTh6j1SdL+PDy/trTpYPjniVkxuOr1fz4ETEzB78N6ar13t/Ff6XNUeO2vFFme5Jd3r4/I7H9PusKpTOZSi23ripqunaq/pUGW466MU3zqgem+UrvPQhYieYeaZpx1vBPEH1E6yqbhlQcUukxtPBx1hyjIQ6Q4Cut/H3DVbK3pRL438LJoqVO6dYMIFR9dr2RQbOt+HihNUiWJ+RD8Jq/N96+YqXNnisyS40DegVNWXdUCqJv4S8y/BRb95G7ieFvqKE+u22X7n6JBWGeiWxXNOK+cE4m/UZkKlzzkc7V292sKflpuaCL/OoqUxI5udCr8qLktMK6Ha48jVTKRhxD/v3WFjWPWbYrouwmT2ksbEdQedUnGMuVGbDmNGNmuL/uV3PmY8YJtW3uiGe1zPtlU/v8sS00ocDNzjqGHE/5vz/Y7qtnG56AvQa5726ruDxpVIWcNGusvg+3s68NEb/jrKRm2qpIKvK5Imsf0U0xWu53f1RtUt12SVui9UAu5tDiuPGkb8VUd13zsM6Yiuy5XId3deptw7HyhWIpl6lCatAVLWbd+vXRrXOaMN9359JSZ/7cVoGrWpoOvlp8xasQXtXb2ZwpgmoYZLujdprwp32TP/8jsfU7bHdzsH1Sool5VHmcSfiFYT0QtE9BwR/YiIxpb8bSkR7SOiPUT08ZLjVxLR7uRv9xKRt7OuEtN75+iQ17pblRYUKa5bUTx313XacXnTFcBZBoB0ta4JqaD293R436xDhVL7dJm7Zqt2x89yrr1wvPHs7P0hPenPUsFSiwX3bdMa/HxW+BT6BpTPlctQVKZqHyL6QwA/YebjRPQNAGDmrxDRdAAPALgKwCQAjwO4iJmHiOgpALcB2A5gE4B7mfnRWu+VtdonRXUqHKIRWEwVCT5KQE3eqxq2KqJ8L0iy8V3aKCPNUlFSrcpqOFxfwzrfo+97/dqenyitNLZVfVit2ifTIi9m/reSX7cD+JPk508B+CEzHwXwayLaB+AqIuoHMIaZtyVGfR9AJ4Ca4m+L5+66TunCKPQNeE8AqTJ3zVbnexRPmzha+YZ+5+gQFty3zdiL60/62LVDfPMAABRgSURBVGQhnQ2YliWW2lKJLPZltakatrZw9Fm+m/X9bBPCFtVEr+tEuM0VvjcD2JD83IbiYJByIDl2LPm5/HhFiGghgIUAMHWqemzcBos27PIu/tdeOF6pHM/HisAti+do3dg/f/FNtHf1Gk/lbQwAwMnePbZv6lgE65LuTdrhleHQyTmVolqjXk5Ms9axo1odW1IZlW/PRyy8ZsyfiB4non+v8O9TJY/pBnAcQLpippLtPMzxijDzWmaeycwzzznnnFqm5h4d0TSpfNHFJCb+8xffDFIJBJzav+fAVy/ErXcs/aBMNKZSWV3SBG57V6914TdZUWsq/D6SqjoOxPJ5lzq0pDKq9vnoL1TT82fmPxju70T0OQCfBPAxPplAOABgSsnDJgM4mByfXOG4V849a0S0bZx1bEun/K6WxK//4jVGq0LTSiATMTftrVOrf086Iyh/j1ixFdKpRNZEq2nZseukqs71ckYzeZ/Z69jno79Q1oTvdQDWAPgvzPxayfFLAfwAJxO+TwCYliR8nwZwC4AdKCZ8/56Za9Y92Ur4pqgmyVy3VqiEbgLPh5iZtgbIaptqMjFr/x5XcXkVfCWZs34Xpna2kPkeAKrozkZ8OwA694/tKignvX2SRO5IAG8kh7Yz818mf+tGMQ9wHMCitKKHiGYC+CcAo1BM9N7CCkbYFn9A/WIOMQDoLNBxWTJXimpzrHJs9G2p9V3Z7t/j6pyGaG+cVeiyLBbzJbIxV/cA6va56HHU8I3dKqFTohbzBQP481yziJdLzzOr51+vZD3nWRLMPu6Z2D3+FJX7xlVzO2nsVgHf3rwuOguuFm3Y5WVxWtaywAX3bcv03qX/ShOI9dK/xwbpQq2Qwp9lEZ8qywq7nbc9sYGqw+S7uV1Di78OIapFtiyeo1XytffQYS+9TLKISloSaoMXVlz/gS2PnJid6/49WZg2cfQpg2LWcFXWyiLX7ZmB4v2omxDXaV9iC9/tYnRo6LAPoBfP9HFRV8JkBaev6a2NunMbtpompPOOre/ZxiphH4ndFF0HIubNmgC3eUWJ+Q+DzgAQYsMXQD+26fNiN00El+Iiwepy96yQ2N7xysYA7rNaSlf4Xe4QVg2da8+1poj4K6B6UYUqC9QVM58Xva1Qjiub8zgzcD3TzFLFk0Iw7/uvi0kPoVD3qur94MOZFPFXQPULawLwUsRVA6X4LFO15Wm7FBQTAQmBq+/N5uf3Kfwxhz7L0XE0fNjopLFbvaHaW+cEkKmRWRZ0VyenDc98XGQ7uuei0DeAu/7lebx15Jjx6zBOHeRsCmGt17HdO6cavoXJhpdfiq+1JUAx5Kkr/D6qjSqhI/zN/rrZV0Q8/zLO7+pV3gAixOIvwFygfAuO7RYFoRLu1ah0o4dILA6H7byH7zCKSR8hnzOSUnRDi77CshL20UBnAAglSCbC6rMaoxQXq1rbxo7C7R+/ONq226Fwca5DFTmYODl5KcjwaaeIvyY6FSx56wsTQjh1BtRazGt6EktaNmISvY6DPAGrjs/HG+fPCxKGiwVX4aoQYmo6YwxR1ZOiukEL4P+civgbEHu/kBRTb8/3oGUj7lzevRMoruRNF3TloWOnDWyU19YiRFjT1EkI+b3reP0hBlNJ+Bqgk1wNlQAGih6Piae0aMMu7PzNm968pfKL3mTQWtKy8RThB4AzaRBLWjbikcHZFV9zZEsTvvFfL891iMhli+dSfCZyyzHZAB7wv/l6KboOTYiQVDXE86+BjkCFnHZmEYdQcVJAv/TQRvfOcWe24u0jxzApsrxBqLUIoXJBKVmu3VDJXUBf+Ee1NuFXf/sJhxZVRsI+hujekCEvxhTTMFDIqbOqAPjo3unb+w3R5jklpKdvuiNYSt6crVC5QRH/DJh4ZKFjz1kEJeRNVUqlz1Ar5i/UJuRMD8gewgo5YAFmg1bIohARfwvoCGroCxTINgCEFoiUSkJxstrnDRzks7Hq+HwR/mGI5bsEsgt/aKfKxP7QNks/fwvo9Nf/+YtvBt80/J7PXGH83HeODkXRjvbuzsvQ39NxSjveR07MxuzBe3HB0fWYPXivCP8w3HT11GiEf8F92zIJf0vYBbHa9qettmNFPH9NTLzpkGGUQt8AFm/YhRMZXiPklHU48tiszTUxzDjLsVGWGjoprbtSum3sKPy866MOLVJHwj4WMRkAYrgpbSz1D9XSohb12r55OGK4pobDRhO5GBwPk8ErBrtTRPwtYhq3jOGCyNumHVmpt0Ehpvj9cGRdcRzLwGYygMVie4pT8SeiLwNYDeAcZn49ObYUwOcBDAG4lZk3J8evBPBPAEYB2ATgNlYwIibxB4oDwAM7XsaQ5vmLIQZoK1wSw2fRIS/tnFMa9fzG8rlNVqTHJvyAQ/EnoikA7gdwCYArmfl1IpoO4AEAVwGYBOBxABcx8xARPQXgNgDbURT/e5n50VrvE5v4p+RxHUCKTa84xoveBB8raWO6BrJS6BvA7Q/uwrEsSaUSYhD+PM/sK+FS/B8C8LcAfgxgZiL+SwGAmVcmj9kMYDmAfgA/ZeZLkuM3ApjDzH9R631iFX8gf0ngcrIutikl1pyAYB+bA2UsrbBNZi9ntjbhlwFW7qripNSTiOYBGGDmZ8v+1Abg5ZLfDyTH2pKfy4/nGhNvZd32/Zi7Zqt9YwzonNGG/p4OK6V06eYxoctcBXfMXbMV7V29mYW/tanoLff3dEQh/MsKu43CVl//9OUOrHFPTfEnoseJ6N8r/PsUgG4AX630tArHeJjj1d57IRHtJKKdr732Wi1Tg2IinnsPHcb5AZf2l7NvZYfWWobhWLRhlwwCdUKhbwAXdPWiPflnI65/09VTsffrHdGESUzXIEybODqaz6CLcdiHiC4D8ASAI8mhyQAOohjn/3OgccI+5Zi0pY0h1pniMu4da1xUOB1X10FM10CWz5iXPJfzUk8i6sfJmP+lAH6AkwnfJwBMSxK+TwO4BcAOFBO+f8/Mm2q9fp7EHzDLAzQT4cZZU6LJBQB28wGl5OXGaURs7/ebEtt3blqdFJOjpoJX8U9+7wZwM4DjABalFT1ENBMnSz0fBXBLHks9a5FFNGNMmrqugonxMzcKLktgYypsSMlyb+ZN+AFZ5BWELPX0sW1WnuK6/XBs3mG94+r7jCm0U0oW4Y/1M9VCxD8Qed2oYjh8rZqN0WvMM752A4tZJPOy5alNRPwjII/7k6rgs8FaMwHfnJ/fG9EnPr+XmAfqLOchlvUHWRDxj4Qs0+zY4+JZ+7kMx8ke/q/jIE/AquPzMeaqz0YrOL4J0eE0dm846wy1XkKQIv4RkTXOGvNMwPZyf8Bs967YhSkrofsUxXwNAtmEP+ZZjAki/pGR1VPL0wWaVahs79sb+wyq0DeALz/4LI6fiOfebG0CVt+QjwE1S24jL11TdRDxj5CsXnLe4pGmA95LIz+Lpgqrp08w4YKj6y1YVhlXFVd5aDOdt5mTjRlnnlqV6yDiHzFZF1LlzVvR3V3MtucvDE/ehD/rorQYF1faRMQ/B2Td7i7WtQEqDHcDm8T8BXXyFEIsJ4vwNxPwYh16+uWI+OcEG4tu8nwzV4vXnqz2eQMH+WysOj5fhN+AeiiVtbVeIW8zHFNE/HOEjZLJeotfuuox1Cjk2SFIsVXhRAC+1SDCD4j45xZbycF6uPlLCV3qGCv1Upteiq2B/8zWJnz905c3jOiniPjnGFsLePKWGDbBVwuDkNSjwFfDxiBfD6GuLIj45xybnm7sC3RcUugbQPePduPwoP2Wxa5pFNEv9A1gyUPPYtDCavF6m/GaIOJfB7jwavO2VsAFlUJrqdDqlqVWolS0q4XxGkXYK1HoG8AdDz+HIzaXhUOEP0XEvw6x2c8l9lWvQn1S6BvA4o27YGsx8+gRzVjxx5c1bIinEiL+dYxpt9BKiLck+KDQN4Avbdgl160HRPzrHJtb76WdFCaNHYXbP36xeFFCZmyEzyohM9baiPg3AC7b+jZCpZDgBldrNBplkVZWRPwbDNl4XQiJK09fwjv6iPg3KK5XxspgINgszayGiL45Iv4Njo/FTzIQNB6unYs8NyuMBWfiT0S3APhrAMcB9DLzkuT4UgCfBzAE4FZm3pwcvxLAPwEYBWATgNtYwQgRf3u4vGHrraeQcCo+t4uUZK4dnIg/Ef0+gG4AHcx8lIgmMvMhIpoO4AEAVwGYBOBxABcx8xARPQXgNgDbURT/e5n50VrvJeJvH1+tEBqtkVa94eM6ydNOYXnDlfhvBLCWmR8vO74UAJh5ZfL7ZgDLAfQD+CkzX5IcvxHAHGb+i1rvJeLvDp/9cMSbi5tC3wDu+pfn8daRY97eU6p23FJN/Fsyvu5FAH6XiFYAeB/Al5n5aQBtKHr2KQeSY8eSn8uPVzN6IYCFADB16tSMpgrVuLvzMtzdeRkKfQNYvXkPBt5+z9l77T10uOKeBQRggST1guAzlFOKePthqSn+RPQ4gN+q8Kfu5PnjAFwN4HcAbCSiC3BynVApPMzxijDzWgBrgaLnX8tWIRudM9pOuxFtLh4bDgawbvv+D2YgMkOwj419brMgFTtxUVP8mfkPqv2NiP4KwMNJwvYpIjoBYAKKHv2UkodOBnAwOT65wnEhUp6767ognmG1GcKo1iasbMCe7KaEbnEtgh8vWWP+fwlgEjN/lYguAvAEgKkApgP4AU4mfJ8AMC1J+D4N4BYAO1BM+P49M2+q9V4S8w/PssJuPLDjZQxFWh48dlQrls+7tKEGhkLfAJY/8jzefs9fjF6FRt04JUZcJXxHAPhHAFcAGEQx5v+T5G/dAG5GsQR0UVrRQ0QzcbLU81EAt0ipZ34JFS8GSvf1fR0HecJp+/oSgBEtTTh6/MQHv+clrxDaY9dh3JmtuPOPGmvQzROyyEtwjs+tFec1PYn/0boWI+j4B8cGuQVfPrbQ2sbupXmHZYXdWL9jP9LbpZJnW2kgLA97+FgN6wtZ1JcPRPyFILjyYH8xciHG03+cdvxN/hA+cnSt9fcTJAmfV1yVegrCsKRlpIDdgWAcThf+4Y4LekhbhfpHxF/wRulAUEq1rQ0FfxABC2blIx8i2EHEXwhOqYepOjt4kz+Es6uEfYThkb0ZBEBi/kLOSAeHeU1PYnXrP2AknVyAdpSbcfuxv7CW8M0zUl8vpEjCV6g7Nv7jN3Htb/4nzsMbeAVnozDuZnznjY/gSKglrBEgoi+UI+IvNByVyjM/feVkbHz65dyVWjbiAjbBDiL+gjAMpauXm4lw46wpH3jQler3Sxc2VctTSBJViAERf0EQhAakmvg3hTBGEARBCIuIvyAIQgMi4i8IgtCAiPgLgiA0ICL+giAIDUhuqn2I6DUAvwnw1hMAvB7gfbOSR7vzaDMgdvsmj3aHtPk/MfM55QdzI/6hIKKdlcqkYiePdufRZkDs9k0e7Y7RZgn7CIIgNCAi/oIgCA2IiH9t8rotVB7tzqPNgNjtmzzaHZ3NEvMXBEFoQMTzFwRBaEBE/AVBEBoQEf8SiOgWItpDRM8T0aqS40uJaF/yt4+XHL+SiHYnf7uXiCiM5QARfZmImIgmlByL1m4iWk1ELxDRc0T0IyIamwe7yyGi6xI79xFRV2h7UohoChH9lIh+lVzPtyXHxxPRFiLam/w/ruQ5Fc97CIiomYj6iOhfk9+jt5uIxhLRQ8l1/SsiuiZqu5lZ/hXzHr8P4HEAI5PfJyb/TwfwLICRAM4H8CKA5uRvTwG4BgABeBTAJwLZPgXAZhQXwU3Ig90A/hBAS/LzNwB8Iw92l32G5sS+CwCMSOyeHvpaTmw7D8BHkp/PAvD/knO7CkBXcrxL5bwHsn8xgB8A+Nfk9+jtBvA9AF9Ifh4BYGzMdovnf5K/AtDDzEcBgJkPJcc/BeCHzHyUmX8NYB+Aq4joPABjmHkbF7/N7wPoDGE4gG8BWAKgNHsftd3M/G/MfDz5dTuAyXmwu4yrAOxj5peYeRDAD1G0PzjM/Aoz/yL5+V0AvwLQhqJ930se9j2cPIcVz7tfq4sQ0WQAHQDuLzkctd1ENAbA7wH4LgAw8yAzv42I7RbxP8lFAH6XiHYQ0f8hot9JjrcBeLnkcQeSY23Jz+XHvUJE8wAMMPOzZX+K2u4ybkbRkwfyZXc1W6OCiNoBzACwA8C5zPwKUBwgAExMHhbTZ7kHRWemdDPm2O2+AMBrAP53Eq66n4hGI2K7W3y+WWiI6HEAv1XhT90onotxAK4G8DsANhLRBSiGGMrhYY5bp4bdd6AYQjntaRWORWM3M/84eUw3gOMA1qdPq2KfN7s1iNGmUyCiDwH4ZwCLmPmdYdIkUXwWIvokgEPM/AwRzVF5SoVjIb6DFgAfAXALM+8gor9DMcxTjeB2N5T4M/MfVPsbEf0VgIeTkMJTRHQCxWZMB1CMqadMBnAwOT65wnHrVLObiC5DMV74bHJTTwbwCyK6ChHbnUJEnwPwSQAfS847EIHdGlSzNQqIqBVF4V/PzA8nh18lovOY+ZUklJaGN2P5LNcCmEdE1wM4A8AYIlqH+O0+AOAAM+9Ifn8IRfGP1+4QiZEY/wH4SwBfS36+CMUpGQG4FKcmZl7CyQTk0yjOFNIE5PWBP0M/TiZ8o7YbwHUAfgngnLLjUdtdZmtLYt/5OJnwvTSkTSW2EYp5kXvKjq/GqQnIVbXOe8DPMAcnE77R2w3gZwAuTn5entgcrd3BL9JY/iU37zoA/w7gFwA+WvK3bhSz8XtQUmECYGby+BcBfBvJiumAn+ED8Y/dbhQTXC8D2JX8+195sLvC57gexUqaF1EMZwW/lhO7ZqMYRniu5BxfD+BsAE8A2Jv8P77WeQ/4GUrFP3q7AVwBYGdyzgsohpGjtVvaOwiCIDQgUu0jCILQgIj4C4IgNCAi/oIgCA2IiL8gCEIDIuIvCILQgIj4C4IgNCAi/oIgCA3I/wfKXQGEmyPtvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.axes()\n",
    "ax.plot(selected_hits.x, selected_hits.y, 'o')\n",
    "ax.plot(track.tx, track.ty, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_module_ids_with_hits(hits, truth, track_id, volume_id, layer_id):\n",
    "    \"\"\"\n",
    "    Returns a numpy array with module_ids of the hits, given track_id, volume_id and layer_id.\n",
    "    \"\"\"\n",
    "    ret = hits.loc[(hits.volume_id == volume_id) & (hits.layer_id == layer_id) & (truth.particle_id == track_id)].module_id\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out how each layer should be padded accordingly (because all layers should in the end image be of length = max_length) we need to take the (max_length - layers_length) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_info(hits, truth, volume_ids=[8, 13, 17]):\n",
    "    \"\"\"\n",
    "    Returns the information of how many modules in each layer and volume.\n",
    "    \"\"\"\n",
    "    volume_ids = [8, 13, 17]\n",
    "    layer_info = []\n",
    "    for v_id in volume_ids:\n",
    "        for l_id in hits.loc[hits.volume_id == v_id].layer_id.unique():\n",
    "            l = max(hits.loc[(hits.volume_id == v_id) & (hits.layer_id == l_id)].module_id.unique())\n",
    "            layer_info.append((v_id, l_id, l))\n",
    "    return layer_info\n",
    "\n",
    "def create_masked_image(hits, truth, track_id, max_length, volume_ids=[8, 13, 17]):\n",
    "    \"\"\"\n",
    "    Returns a masked image of the track\n",
    "    \"\"\"\n",
    "    layer_info = get_layer_info(hits, truth, volume_ids)\n",
    "    nr_layers = len(layer_info)\n",
    "    masked_image = np.zeros((max_length, nr_layers))\n",
    "    for i in range(nr_layers):\n",
    "        layer_length = layer_info[i][2]\n",
    "        pad_length = int((max_length - layer_length) / 2) - 1\n",
    "        #print(\"Layer length:\", layer_length, \"Pad length:\", pad_length)\n",
    "        #print(\"Volume id:\", layer_info[i][0], \"Layer id:\", layer_info[i][1])\n",
    "        module_ids = find_module_ids_with_hits(hits, truth, track_id, layer_info[i][0], layer_info[i][1])\n",
    "        if len(module_ids) > 0:\n",
    "            mean_id = int(np.mean(module_ids))\n",
    "            masked_image[mean_id + pad_length, i] += 1\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 2, 224),\n",
       " (8, 4, 448),\n",
       " (8, 6, 728),\n",
       " (8, 8, 1092),\n",
       " (13, 2, 840),\n",
       " (13, 4, 1176),\n",
       " (13, 6, 1638),\n",
       " (13, 8, 2142),\n",
       " (17, 2, 2520),\n",
       " (17, 4, 3192)]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_layer_info(hits, truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function filters the tracks such that we only look at track ids which are guaranteed to have atleast n hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_valid_tracks(hits, truth, hits_threshhold=10):\n",
    "    cond = (hits['volume_id'] == 8) | (hits['volume_id'] == 13) | (hits['volume_id'] == 17)\n",
    "    tracks = truth.loc[cond].particle_id.unique()\n",
    "    valid_tracks = []\n",
    "    for track in tracks:\n",
    "        if track == 0:\n",
    "            continue\n",
    "        #nr_hits = truth.loc[cond & (truth.particle_id == track)].shape[0]\n",
    "        invalid_track = False\n",
    "        volume_ids = [8, 13, 17]\n",
    "        nr_hits = 0\n",
    "        for v_id in volume_ids:\n",
    "            for l_id in hits.loc[hits.volume_id == v_id].layer_id.unique():\n",
    "                h = find_module_ids_with_hits(hits, truth, track, v_id, l_id)\n",
    "                if len(h) > 0:\n",
    "                    nr_hits += 1\n",
    "                else:\n",
    "                    invalid_track = True\n",
    "        \n",
    "        \n",
    "        if nr_hits >= hits_threshhold and not invalid_track:\n",
    "            valid_tracks.append(track)\n",
    "    return valid_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tracks = select_valid_tracks(hits, truth, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1086"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\n",
      "[194]\n",
      "[315]\n",
      "[394]\n",
      "[363]\n",
      "[452]\n",
      "[552]\n",
      "[620]\n",
      "[731]\n",
      "[623]\n"
     ]
    }
   ],
   "source": [
    "volume_ids = [8, 13, 17]\n",
    "for v_id in volume_ids:\n",
    "    for l_id in hits.loc[hits.volume_id == v_id].layer_id.unique():\n",
    "        h = find_module_ids_with_hits(hits, truth, valid_tracks[39], v_id, l_id)\n",
    "        print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of image: 3192 x 10\n"
     ]
    }
   ],
   "source": [
    "cond = (hits['volume_id'] == 8) | (hits['volume_id'] == 13) | (hits['volume_id'] == 17)\n",
    "max_length = max(hits.loc[cond].module_id.unique())\n",
    "print(\"Dimension of image:\", max_length, \"x\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.ndarray(shape=(len(valid_tracks), max_length, 10, 1))\n",
    "train_y = np.empty((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = j\n",
    "for track_id in tqdm(valid_tracks):\n",
    "    if track_id == 0:\n",
    "        continue\n",
    "    image = create_masked_image(hits, truth, track_id, max_length)\n",
    "    train_X[i] = np.reshape(image, (image.shape[0], image.shape[1], 1))\n",
    "    i += 1\n",
    "    t = truth.loc[cond & (truth.particle_id == track_id)]\n",
    "    px = t['tpx'].mean()\n",
    "    py = t['tpy'].mean()\n",
    "    p = np.sqrt(px**2 + py**2)\n",
    "    train_y = np.append(train_y, [p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_y, (len(train_y), 1))\n",
    "#train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], train_X.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 106\n",
    "im = create_masked_image(hits, truth, valid_tracks[k], max_length)#np.reshape(train_X2[k], (train_X2[k].shape[0], train_X2[k].shape[1]))#\n",
    "im = im.astype(int)\n",
    "plt.imshow(np.reshape(im, (im.shape[0], im.shape[1])), aspect=\"auto\")\n",
    "plt.savefig('myimage.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(8, (3, 3), activation=\"relu\", input_shape=(train_X.shape[1], train_X.shape[2], train_X.shape[3])),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(20, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    #optimizer = keras.optimizers.RMSprop(learning_rate=0.00001) #0.00001 works good\n",
    "    model.compile(loss='mse', optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 3190, 8, 8)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1595, 4, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 1593, 2, 16)       1168      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 50976)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                1019540   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,020,809\n",
      "Trainable params: 1,020,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1893, 3192, 10, 1)\n",
      "(1893, 1)\n",
      "Train on 1703 samples, validate on 190 samples\n",
      "Epoch 1/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 4.1906 - val_loss: 0.4422\n",
      "Epoch 2/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 4.0378 - val_loss: 0.3257\n",
      "Epoch 3/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 3.8891 - val_loss: 0.4249\n",
      "Epoch 4/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 3.7960 - val_loss: 0.4423\n",
      "Epoch 5/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 3.5158 - val_loss: 0.6887\n",
      "Epoch 6/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 3.3540 - val_loss: 0.7372\n",
      "Epoch 7/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 3.1118 - val_loss: 0.6226\n",
      "Epoch 8/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 2.8589 - val_loss: 0.9202\n",
      "Epoch 9/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 2.6687 - val_loss: 0.5555\n",
      "Epoch 10/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 2.5526 - val_loss: 1.3609\n",
      "Epoch 11/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 2.3322 - val_loss: 0.3127\n",
      "Epoch 12/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 2.0554 - val_loss: 0.8974\n",
      "Epoch 13/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 1.7510 - val_loss: 0.3690\n",
      "Epoch 14/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 1.4354 - val_loss: 0.5676\n",
      "Epoch 15/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 1.4184 - val_loss: 0.3650\n",
      "Epoch 16/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 1.2068 - val_loss: 0.4085\n",
      "Epoch 17/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.9586 - val_loss: 0.4236\n",
      "Epoch 18/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.7335 - val_loss: 0.3717\n",
      "Epoch 19/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.5999 - val_loss: 0.3591\n",
      "Epoch 20/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.4223 - val_loss: 0.9930\n",
      "Epoch 21/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.3742 - val_loss: 0.4495\n",
      "Epoch 22/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.2638 - val_loss: 0.5708\n",
      "Epoch 23/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1587 - val_loss: 0.5261\n",
      "Epoch 24/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1063 - val_loss: 0.5718\n",
      "Epoch 25/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0914 - val_loss: 0.4979\n",
      "Epoch 26/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0709 - val_loss: 0.5153\n",
      "Epoch 27/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0556 - val_loss: 0.5047\n",
      "Epoch 28/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0425 - val_loss: 0.5140\n",
      "Epoch 29/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0372 - val_loss: 0.5020\n",
      "Epoch 30/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0373 - val_loss: 0.5062\n",
      "Epoch 31/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0391 - val_loss: 0.5181\n",
      "Epoch 32/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0334 - val_loss: 0.5188\n",
      "Epoch 33/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0344 - val_loss: 0.4983\n",
      "Epoch 34/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0348 - val_loss: 0.5412\n",
      "Epoch 35/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0372 - val_loss: 0.5271\n",
      "Epoch 36/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0419 - val_loss: 0.5263\n",
      "Epoch 37/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0452 - val_loss: 0.5154\n",
      "Epoch 38/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0563 - val_loss: 0.5204\n",
      "Epoch 39/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0459 - val_loss: 0.5339\n",
      "Epoch 40/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0471 - val_loss: 0.4974\n",
      "Epoch 41/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0540 - val_loss: 0.5409\n",
      "Epoch 42/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0408 - val_loss: 0.5407\n",
      "Epoch 43/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0284 - val_loss: 0.5473\n",
      "Epoch 44/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0268 - val_loss: 0.5261\n",
      "Epoch 45/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0255 - val_loss: 0.5373\n",
      "Epoch 46/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0247 - val_loss: 0.5320\n",
      "Epoch 47/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0250 - val_loss: 0.4978\n",
      "Epoch 48/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0245 - val_loss: 0.5476\n",
      "Epoch 49/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0219 - val_loss: 0.5880\n",
      "Epoch 50/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0227 - val_loss: 0.5162\n",
      "Epoch 51/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0246 - val_loss: 0.6376\n",
      "Epoch 52/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0234 - val_loss: 0.5438\n",
      "Epoch 53/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0261 - val_loss: 0.6742\n",
      "Epoch 54/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0274 - val_loss: 0.5080\n",
      "Epoch 55/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0251 - val_loss: 0.4816\n",
      "Epoch 56/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0256 - val_loss: 0.6511\n",
      "Epoch 57/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0308 - val_loss: 0.5106\n",
      "Epoch 58/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0287 - val_loss: 0.4875\n",
      "Epoch 59/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0351 - val_loss: 0.5363\n",
      "Epoch 60/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0361 - val_loss: 0.5580\n",
      "Epoch 61/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0421 - val_loss: 0.5377\n",
      "Epoch 62/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0320 - val_loss: 0.5482\n",
      "Epoch 63/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0360 - val_loss: 0.5218\n",
      "Epoch 64/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0891 - val_loss: 0.5006\n",
      "Epoch 65/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0691 - val_loss: 0.7167\n",
      "Epoch 66/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1162 - val_loss: 0.4321\n",
      "Epoch 67/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1050 - val_loss: 0.5999\n",
      "Epoch 68/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1268 - val_loss: 0.5267\n",
      "Epoch 69/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0866 - val_loss: 0.5600\n",
      "Epoch 70/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1160 - val_loss: 0.5630\n",
      "Epoch 71/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0765 - val_loss: 0.4721\n",
      "Epoch 72/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1045 - val_loss: 0.7542\n",
      "Epoch 73/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0324 - val_loss: 0.5764\n",
      "Epoch 74/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0200 - val_loss: 0.5816\n",
      "Epoch 75/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0192 - val_loss: 0.4943\n",
      "Epoch 76/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0256 - val_loss: 0.5683\n",
      "Epoch 77/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0292 - val_loss: 0.5336\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0345 - val_loss: 0.5500\n",
      "Epoch 79/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0283 - val_loss: 0.5334\n",
      "Epoch 80/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0246 - val_loss: 0.5829\n",
      "Epoch 81/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0212 - val_loss: 0.5317\n",
      "Epoch 82/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0191 - val_loss: 0.5694\n",
      "Epoch 83/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0163 - val_loss: 0.5419\n",
      "Epoch 84/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0157 - val_loss: 0.5524\n",
      "Epoch 85/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0202 - val_loss: 0.5506\n",
      "Epoch 86/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0273 - val_loss: 0.5042\n",
      "Epoch 87/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0671 - val_loss: 0.6433\n",
      "Epoch 88/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0839 - val_loss: 0.5422\n",
      "Epoch 89/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1527 - val_loss: 0.4763\n",
      "Epoch 90/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0894 - val_loss: 0.5269\n",
      "Epoch 91/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0363 - val_loss: 0.5461\n",
      "Epoch 92/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0427 - val_loss: 0.5726\n",
      "Epoch 93/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0334 - val_loss: 0.4640\n",
      "Epoch 94/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0484 - val_loss: 0.7480\n",
      "Epoch 95/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0487 - val_loss: 0.4572\n",
      "Epoch 96/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0592 - val_loss: 0.7308\n",
      "Epoch 97/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.4689\n",
      "Epoch 98/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0680 - val_loss: 0.5200\n",
      "Epoch 99/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0558 - val_loss: 0.5516\n",
      "Epoch 100/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0711 - val_loss: 0.5678\n",
      "Epoch 101/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.4618\n",
      "Epoch 102/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0831 - val_loss: 0.5475\n",
      "Epoch 103/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0482 - val_loss: 0.4976\n",
      "Epoch 104/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0530 - val_loss: 0.5523\n",
      "Epoch 105/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0289 - val_loss: 0.5152\n",
      "Epoch 106/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0303 - val_loss: 0.5597\n",
      "Epoch 107/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0177 - val_loss: 0.5169\n",
      "Epoch 108/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0136 - val_loss: 0.5212\n",
      "Epoch 109/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0129 - val_loss: 0.5145\n",
      "Epoch 110/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0151 - val_loss: 0.5565\n",
      "Epoch 111/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0194 - val_loss: 0.4619\n",
      "Epoch 112/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0283 - val_loss: 0.6304\n",
      "Epoch 113/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0262 - val_loss: 0.5064\n",
      "Epoch 114/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0367 - val_loss: 0.6416\n",
      "Epoch 115/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0416 - val_loss: 0.4780\n",
      "Epoch 116/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0436 - val_loss: 0.5503\n",
      "Epoch 117/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0279 - val_loss: 0.5197\n",
      "Epoch 118/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0313 - val_loss: 0.5878\n",
      "Epoch 119/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0314 - val_loss: 0.5095\n",
      "Epoch 120/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0361 - val_loss: 0.5439\n",
      "Epoch 121/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0308 - val_loss: 0.5429\n",
      "Epoch 122/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0493 - val_loss: 0.6160\n",
      "Epoch 123/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0724 - val_loss: 0.5483\n",
      "Epoch 124/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1167 - val_loss: 0.6587\n",
      "Epoch 125/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1034 - val_loss: 0.5219\n",
      "Epoch 126/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1578 - val_loss: 0.5824\n",
      "Epoch 127/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0545 - val_loss: 0.6738\n",
      "Epoch 128/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0728 - val_loss: 0.4855\n",
      "Epoch 129/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0429 - val_loss: 0.5223\n",
      "Epoch 130/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0427 - val_loss: 0.5876\n",
      "Epoch 131/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0366 - val_loss: 0.4419\n",
      "Epoch 132/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0400 - val_loss: 0.5315\n",
      "Epoch 133/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0276 - val_loss: 0.4624\n",
      "Epoch 134/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0276 - val_loss: 0.5329\n",
      "Epoch 135/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0225 - val_loss: 0.4740\n",
      "Epoch 136/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0241 - val_loss: 0.5529\n",
      "Epoch 137/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0213 - val_loss: 0.4573\n",
      "Epoch 138/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0301 - val_loss: 0.5808\n",
      "Epoch 139/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0287 - val_loss: 0.4738\n",
      "Epoch 140/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0316 - val_loss: 0.5956\n",
      "Epoch 141/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0328 - val_loss: 0.4637\n",
      "Epoch 142/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0441 - val_loss: 0.4683\n",
      "Epoch 143/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0483 - val_loss: 0.6554\n",
      "Epoch 144/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0845 - val_loss: 0.4661\n",
      "Epoch 145/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0642 - val_loss: 0.5839\n",
      "Epoch 146/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0746 - val_loss: 0.4502\n",
      "Epoch 147/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0528 - val_loss: 0.6553\n",
      "Epoch 148/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0647 - val_loss: 0.5420\n",
      "Epoch 149/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0528 - val_loss: 0.5494\n",
      "Epoch 150/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0707 - val_loss: 0.4971\n",
      "Epoch 151/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0408 - val_loss: 0.5038\n",
      "Epoch 152/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0186 - val_loss: 0.5279\n",
      "Epoch 153/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0071 - val_loss: 0.5381\n",
      "Epoch 154/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0057 - val_loss: 0.5371\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0120 - val_loss: 0.5480\n",
      "Epoch 156/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0105 - val_loss: 0.5335\n",
      "Epoch 157/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0094 - val_loss: 0.5428\n",
      "Epoch 158/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0112 - val_loss: 0.5116\n",
      "Epoch 159/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0156 - val_loss: 0.5212\n",
      "Epoch 160/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0191 - val_loss: 0.5160\n",
      "Epoch 161/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0285 - val_loss: 0.5182\n",
      "Epoch 162/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0361 - val_loss: 0.5173\n",
      "Epoch 163/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0668 - val_loss: 0.4626\n",
      "Epoch 164/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0732 - val_loss: 0.5091\n",
      "Epoch 165/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1000 - val_loss: 0.5072\n",
      "Epoch 166/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0534 - val_loss: 0.5718\n",
      "Epoch 167/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0649 - val_loss: 0.4984\n",
      "Epoch 168/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0390 - val_loss: 0.5414\n",
      "Epoch 169/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0446 - val_loss: 0.6046\n",
      "Epoch 170/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0488 - val_loss: 0.5358\n",
      "Epoch 171/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0728 - val_loss: 0.5281\n",
      "Epoch 172/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0531 - val_loss: 0.6391\n",
      "Epoch 173/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0859 - val_loss: 0.5429\n",
      "Epoch 174/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0742 - val_loss: 0.4789\n",
      "Epoch 175/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0890 - val_loss: 0.5407\n",
      "Epoch 176/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0533 - val_loss: 0.5086\n",
      "Epoch 177/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0472 - val_loss: 0.6163\n",
      "Epoch 178/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0274 - val_loss: 0.5213\n",
      "Epoch 179/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0337 - val_loss: 0.5760\n",
      "Epoch 180/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0278 - val_loss: 0.5453\n",
      "Epoch 181/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0284 - val_loss: 0.5902\n",
      "Epoch 182/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0245 - val_loss: 0.5422\n",
      "Epoch 183/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0236 - val_loss: 0.5759\n",
      "Epoch 184/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0154 - val_loss: 0.5153\n",
      "Epoch 185/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0151 - val_loss: 0.5854\n",
      "Epoch 186/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0144 - val_loss: 0.5567\n",
      "Epoch 187/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0189 - val_loss: 0.5654\n",
      "Epoch 188/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0201 - val_loss: 0.5664\n",
      "Epoch 189/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0289 - val_loss: 0.4949\n",
      "Epoch 190/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0316 - val_loss: 0.5225\n",
      "Epoch 191/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0477 - val_loss: 0.5511\n",
      "Epoch 192/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0406 - val_loss: 0.4868\n",
      "Epoch 193/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0667 - val_loss: 0.5900\n",
      "Epoch 194/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0702 - val_loss: 0.5750\n",
      "Epoch 195/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1001 - val_loss: 0.6156\n",
      "Epoch 196/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.4945\n",
      "Epoch 197/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0723 - val_loss: 0.5124\n",
      "Epoch 198/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0497 - val_loss: 0.5653\n",
      "Epoch 199/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0516 - val_loss: 0.5836\n",
      "Epoch 200/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0341 - val_loss: 0.5015\n",
      "Epoch 201/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0396 - val_loss: 0.5741\n",
      "Epoch 202/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0286 - val_loss: 0.5675\n",
      "Epoch 203/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0342 - val_loss: 0.5231\n",
      "Epoch 204/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0277 - val_loss: 0.5809\n",
      "Epoch 205/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0309 - val_loss: 0.5750\n",
      "Epoch 206/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0244 - val_loss: 0.5116\n",
      "Epoch 207/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0326 - val_loss: 0.6094\n",
      "Epoch 208/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0283 - val_loss: 0.4720\n",
      "Epoch 209/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0359 - val_loss: 0.5808\n",
      "Epoch 210/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0259 - val_loss: 0.5325\n",
      "Epoch 211/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0221 - val_loss: 0.5572\n",
      "Epoch 212/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0150 - val_loss: 0.5902\n",
      "Epoch 213/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0190 - val_loss: 0.5500\n",
      "Epoch 214/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0216 - val_loss: 0.5605\n",
      "Epoch 215/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0306 - val_loss: 0.6925\n",
      "Epoch 216/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0355 - val_loss: 0.4963\n",
      "Epoch 217/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0509 - val_loss: 0.6301\n",
      "Epoch 218/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0622 - val_loss: 0.6036\n",
      "Epoch 219/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1088 - val_loss: 0.5622\n",
      "Epoch 220/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0883 - val_loss: 0.5413\n",
      "Epoch 221/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1015 - val_loss: 0.6070\n",
      "Epoch 222/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0432 - val_loss: 0.5174\n",
      "Epoch 223/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0499 - val_loss: 0.5850\n",
      "Epoch 224/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0292 - val_loss: 0.5259\n",
      "Epoch 225/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0282 - val_loss: 0.6042\n",
      "Epoch 226/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0158 - val_loss: 0.4928\n",
      "Epoch 227/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0119 - val_loss: 0.5949\n",
      "Epoch 228/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.5176\n",
      "Epoch 229/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.5498\n",
      "Epoch 230/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0070 - val_loss: 0.5166\n",
      "Epoch 231/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.6142\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0071 - val_loss: 0.5242\n",
      "Epoch 233/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0070 - val_loss: 0.5442\n",
      "Epoch 234/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0077 - val_loss: 0.5609\n",
      "Epoch 235/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0101 - val_loss: 0.5553\n",
      "Epoch 236/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0124 - val_loss: 0.5313\n",
      "Epoch 237/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0204 - val_loss: 0.5906\n",
      "Epoch 238/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0241 - val_loss: 0.4926\n",
      "Epoch 239/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0562 - val_loss: 0.6286\n",
      "Epoch 240/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1116 - val_loss: 0.6680\n",
      "Epoch 241/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.2420 - val_loss: 0.7322\n",
      "Epoch 242/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1602 - val_loss: 0.9074\n",
      "Epoch 243/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.4021 - val_loss: 0.8732\n",
      "Epoch 244/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.7052 - val_loss: 0.6176\n",
      "Epoch 245/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.8077 - val_loss: 0.9398\n",
      "Epoch 246/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 2.5270 - val_loss: 0.3063\n",
      "Epoch 247/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 3.9306 - val_loss: 0.2977\n",
      "Epoch 248/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 3.1247 - val_loss: 0.6017\n",
      "Epoch 249/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 2.9407 - val_loss: 1.1006\n",
      "Epoch 250/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 2.7880 - val_loss: 0.6132\n",
      "Epoch 251/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 2.6521 - val_loss: 0.8029\n",
      "Epoch 252/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 2.3547 - val_loss: 0.7177\n",
      "Epoch 253/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.3147 - val_loss: 0.8819\n",
      "Epoch 254/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.9506 - val_loss: 0.8140\n",
      "Epoch 255/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1856 - val_loss: 0.8288\n",
      "Epoch 256/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1940 - val_loss: 0.8632\n",
      "Epoch 257/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.4086 - val_loss: 1.0014\n",
      "Epoch 258/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.2759 - val_loss: 0.6994\n",
      "Epoch 259/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 1.4057 - val_loss: 0.6918\n",
      "Epoch 260/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.7061 - val_loss: 0.6390\n",
      "Epoch 261/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.2337 - val_loss: 1.0249\n",
      "Epoch 262/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1131 - val_loss: 1.0336\n",
      "Epoch 263/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0855 - val_loss: 0.9405\n",
      "Epoch 264/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0783 - val_loss: 0.8866\n",
      "Epoch 265/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0747 - val_loss: 0.8962\n",
      "Epoch 266/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0723 - val_loss: 0.8827\n",
      "Epoch 267/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0710 - val_loss: 0.8884\n",
      "Epoch 268/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0702 - val_loss: 0.8890\n",
      "Epoch 269/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0698 - val_loss: 0.8887\n",
      "Epoch 270/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0691 - val_loss: 0.8903\n",
      "Epoch 271/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0688 - val_loss: 0.8945\n",
      "Epoch 272/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0685 - val_loss: 0.8913\n",
      "Epoch 273/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0684 - val_loss: 0.8918\n",
      "Epoch 274/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0683 - val_loss: 0.8905\n",
      "Epoch 275/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0682 - val_loss: 0.8921\n",
      "Epoch 276/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0681 - val_loss: 0.8896\n",
      "Epoch 277/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0681 - val_loss: 0.8888\n",
      "Epoch 278/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0680 - val_loss: 0.8892\n",
      "Epoch 279/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0680 - val_loss: 0.8952\n",
      "Epoch 280/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0681 - val_loss: 0.8897\n",
      "Epoch 281/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0680 - val_loss: 0.8895\n",
      "Epoch 282/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8811\n",
      "Epoch 283/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8894\n",
      "Epoch 284/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8895\n",
      "Epoch 285/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8952\n",
      "Epoch 286/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8865\n",
      "Epoch 287/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0678 - val_loss: 0.8879\n",
      "Epoch 288/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0678 - val_loss: 0.8867\n",
      "Epoch 289/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0678 - val_loss: 0.8898\n",
      "Epoch 290/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8877\n",
      "Epoch 291/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0679 - val_loss: 0.8887\n",
      "Epoch 292/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0680 - val_loss: 0.8781\n",
      "Epoch 293/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0681 - val_loss: 0.8934\n",
      "Epoch 294/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0683 - val_loss: 0.8883\n",
      "Epoch 295/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0685 - val_loss: 0.8773\n",
      "Epoch 296/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0687 - val_loss: 0.8946\n",
      "Epoch 297/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0699 - val_loss: 0.8768\n",
      "Epoch 298/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0700 - val_loss: 0.8991\n",
      "Epoch 299/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0700 - val_loss: 0.8751\n",
      "Epoch 300/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0721 - val_loss: 0.8782\n",
      "Epoch 301/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0708 - val_loss: 0.9101\n",
      "Epoch 302/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0731 - val_loss: 0.8735\n",
      "Epoch 303/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0764 - val_loss: 0.9151\n",
      "Epoch 304/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0888 - val_loss: 0.9584\n",
      "Epoch 305/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1038 - val_loss: 0.9435\n",
      "Epoch 306/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1040 - val_loss: 1.0070\n",
      "Epoch 307/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1970 - val_loss: 1.1320\n",
      "Epoch 308/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.3386 - val_loss: 0.8110\n",
      "Epoch 309/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.2926 - val_loss: 0.8630\n",
      "Epoch 310/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.3746 - val_loss: 0.7943\n",
      "Epoch 311/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1594 - val_loss: 0.7871\n",
      "Epoch 312/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0773 - val_loss: 0.9904\n",
      "Epoch 313/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.3253 - val_loss: 0.8386\n",
      "Epoch 314/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1377 - val_loss: 1.1055\n",
      "Epoch 315/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0741 - val_loss: 0.8416\n",
      "Epoch 316/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0599 - val_loss: 0.9233\n",
      "Epoch 317/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0535 - val_loss: 0.8686\n",
      "Epoch 318/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0512 - val_loss: 0.9037\n",
      "Epoch 319/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0500 - val_loss: 0.8953\n",
      "Epoch 320/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0495 - val_loss: 0.9003\n",
      "Epoch 321/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0494 - val_loss: 0.8900\n",
      "Epoch 322/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0487 - val_loss: 0.8939\n",
      "Epoch 323/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0486 - val_loss: 0.8970\n",
      "Epoch 324/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0486 - val_loss: 0.8945\n",
      "Epoch 325/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8935\n",
      "Epoch 326/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8949\n",
      "Epoch 327/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8912\n",
      "Epoch 328/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.9089\n",
      "Epoch 329/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8926\n",
      "Epoch 330/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8936\n",
      "Epoch 331/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8909\n",
      "Epoch 332/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8965\n",
      "Epoch 333/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.9041\n",
      "Epoch 334/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0486 - val_loss: 0.9003\n",
      "Epoch 335/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0485 - val_loss: 0.8928\n",
      "Epoch 336/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0486 - val_loss: 0.8989\n",
      "Epoch 337/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0487 - val_loss: 0.8976\n",
      "Epoch 338/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0486 - val_loss: 0.9011\n",
      "Epoch 339/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0487 - val_loss: 0.8955\n",
      "Epoch 340/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0488 - val_loss: 0.8949\n",
      "Epoch 341/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0491 - val_loss: 0.9070\n",
      "Epoch 342/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0494 - val_loss: 0.8864\n",
      "Epoch 343/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0497 - val_loss: 0.8746\n",
      "Epoch 344/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0502 - val_loss: 0.8740\n",
      "Epoch 345/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0506 - val_loss: 0.9006\n",
      "Epoch 346/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0526 - val_loss: 0.8753\n",
      "Epoch 347/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0594 - val_loss: 0.8672\n",
      "Epoch 348/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0702 - val_loss: 0.8643\n",
      "Epoch 349/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0861 - val_loss: 0.8454\n",
      "Epoch 350/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1529 - val_loss: 1.0353\n",
      "Epoch 351/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1454 - val_loss: 0.8445\n",
      "Epoch 352/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.2137 - val_loss: 0.8936\n",
      "Epoch 353/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1494 - val_loss: 0.7172\n",
      "Epoch 354/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1615 - val_loss: 1.0943\n",
      "Epoch 355/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1196 - val_loss: 1.0228\n",
      "Epoch 356/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1449 - val_loss: 0.7537\n",
      "Epoch 357/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1169 - val_loss: 0.8408\n",
      "Epoch 358/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.1049 - val_loss: 0.8456\n",
      "Epoch 359/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0653 - val_loss: 0.8232\n",
      "Epoch 360/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0564 - val_loss: 0.8925\n",
      "Epoch 361/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0496 - val_loss: 0.8580\n",
      "Epoch 362/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0477 - val_loss: 0.8709\n",
      "Epoch 363/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0469 - val_loss: 0.8264\n",
      "Epoch 364/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0469 - val_loss: 0.8686\n",
      "Epoch 365/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0453 - val_loss: 0.8640\n",
      "Epoch 366/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0454 - val_loss: 0.8682\n",
      "Epoch 367/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0448 - val_loss: 0.8479\n",
      "Epoch 368/1000\n",
      "1703/1703 [==============================] - 3s 2ms/step - loss: 0.0443 - val_loss: 0.8904\n",
      "Epoch 369/1000\n",
      "1703/1703 [==============================] - 4s 2ms/step - loss: 0.0436 - val_loss: 0.8891\n",
      "Epoch 370/1000\n",
      "1664/1703 [============================>.] - ETA: 0s - loss: 0.0436"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-87885a6f6a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "history = model.fit(train_X, train_y, validation_split=0.1, epochs=EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/real [[0.9020727]] [1.33578894]\n"
     ]
    }
   ],
   "source": [
    "i = 421\n",
    "pred = model.predict(np.reshape(train_X[i], (1, max_length, 10, 1)))\n",
    "real = train_y[i]\n",
    "print(\"pred/real\", pred, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
